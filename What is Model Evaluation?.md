# What is Model Evaluation?🧑‍🔬
In-Sample evaluation tells us how well our model will fit the data used to train it.

Problem?
- It does not tell us how well the trained model can be used to predict new data.
Solution?
- In-Sample data or training data 
- Out-of-sample evaluation or test set

### 🧪Training and Testing Data Set:🏃
- Building and Training the model with training set
- Once training is done, test data can be used to assess the performance of predictive model 

### Generizational Performance:
- Generizational error is measure of how well our data does at predicting previously unseen data

### Cross Validation:
- Most common out-of-sample evaluation metrics 
- returns the prediction that was obtained for each element when it was in the test set

### Overfitting, Underfitting and Model Selection:
- Underfitting : model is too simple to fit the data 
- Overfitting : model is too flexible that it fits the noise rather than the function 

### Ridge Regression:
Ridge regression is a regression that is employed in a Multiple regression model when Multicollinearity occurs. Multicollinearity is when there is a strong relationship among the independent variables. Ridge regression is very common with polynomial regression.

(Prevents Overfitting)

### Grid Search:
Time-efficient tuning technique that exhaustively computes the optimum values of hyperparameters performed on specific parameter values of estimators.

